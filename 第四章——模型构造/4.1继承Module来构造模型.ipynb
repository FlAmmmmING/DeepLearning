{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    # 声明带有模型参数的层,这里声明了两个全连接层\n",
    "    def __init__(self, **kwargs):\n",
    "        # 调用 MLP 父类 Block 的构造函数来进行必要的初始化。这样在构造实例时还可以指定其他函数 \n",
    "        # 参数,如“模型参数的访问、初始化和共享” 一节将介绍的模型参数params\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.hidden = nn.Linear(28 * 28, 256) # 隐藏层\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(256, 10) # 输出层\n",
    "        \n",
    "    # 定义模型的前向计算,即如何根据输入x计算返回所需要的模型输出\n",
    "    def forward(self, x):\n",
    "        a = self.act(self.hidden(x))\n",
    "        return self.output(a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T08:15:50.928506900Z",
     "start_time": "2024-11-13T08:15:48.612038300Z"
    }
   },
   "id": "fa8ab4dadb6e7059",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 实例化 net 变量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c97ffc4f38d6c2cf"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (act): ReLU()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "tensor([[0.3339, 0.6754, 0.3144,  ..., 0.8471, 0.2965, 0.9148],\n",
      "        [0.6417, 0.7926, 0.7024,  ..., 0.9714, 0.7874, 0.8434]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[-0.0315,  0.0535, -0.1689, -0.0216, -0.0975, -0.1673,  0.1781, -0.1765,\n          0.0267,  0.0674],\n        [-0.0280,  0.0417,  0.0613, -0.1011, -0.2433,  0.0280,  0.2121, -0.1117,\n         -0.1569, -0.0076]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(2, 28 * 28)\n",
    "net = MLP()\n",
    "print(net)\n",
    "print(X)\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T08:18:46.212437500Z",
     "start_time": "2024-11-13T08:18:46.168383600Z"
    }
   },
   "id": "3498285c22166b9e",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3339, 0.6754, 0.3144,  ..., 0.8471, 0.2965, 0.9148],\n",
      "        [0.6417, 0.7926, 0.7024,  ..., 0.9714, 0.7874, 0.8434]])\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T08:18:48.414206900Z",
     "start_time": "2024-11-13T08:18:48.404017900Z"
    }
   },
   "id": "571907960c753f42",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sequential 类"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35f1985e4bb91b6f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(MySequential, self).__init__()\n",
    "        if len(args) == 1 and isinstance(args[0], OrderedDict): # 如果传入的是一个OrderedDict\n",
    "            for key, module in args[0].items():\n",
    "                self.add_module(key, module) # add_module方法会将module添加进self._modules(一个OrderedDict)\n",
    "            else: # 传入的是某个Module\n",
    "                for idx, module in enumerate(args):\n",
    "                    self.add_module(str(idx), module)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # self._modules 返回一个 OrderedDict\n",
    "        for module in self._modules.values():\n",
    "            input = module(input)\n",
    "        return input"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T08:31:56.569331900Z",
     "start_time": "2024-11-13T08:31:56.542710400Z"
    }
   },
   "id": "1e59d70e5080bdd8",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ 0.0567, -0.0531, -0.2672, -0.0322, -0.2290, -0.0737,  0.1635, -0.0397,\n         -0.0963, -0.0412],\n        [ 0.2016,  0.2351, -0.1288, -0.1535, -0.1899, -0.1304,  0.1921,  0.0831,\n         -0.1079,  0.0674]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(28 * 28, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10),\n",
    ")\n",
    "print(net)\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T08:33:22.049049Z",
     "start_time": "2024-11-13T08:33:22.035047900Z"
    }
   },
   "id": "f3a96f529c1f85be",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ModuleList 类"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8841cf01687977e4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=256, out_features=10, bias=True)\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = nn.ModuleList([\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU()\n",
    "])\n",
    "net.append(nn.Linear(256, 10)) # 类似 List 操作\n",
    "print(net[-1])\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T08:34:35.062157700Z",
     "start_time": "2024-11-13T08:34:35.047153900Z"
    }
   },
   "id": "f748ff1499b2230b",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ModuleDict 类"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41c51afb1e8bfde"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "ModuleDict(\n",
      "  (linear): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = nn.ModuleDict({\n",
    "    'linear': nn.Linear(784, 256),\n",
    "    'relu': nn.ReLU(),\n",
    "})\n",
    "net['output'] = nn.Linear(256, 10)\n",
    "print(net['linear'])\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T08:36:15.894168100Z",
     "start_time": "2024-11-13T08:36:15.851143Z"
    }
   },
   "id": "5846a45dd7f1f98c",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 构造复杂的模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "821385fa5cc7f3ee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class FancyMLP(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(FancyMLP, self).__init__(**kwargs)\n",
    "        \n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=False) # 不可训练参数\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        # 使用创建的常数参数,以及nn.functional中的relu函数和mm函数\n",
    "        x = nn.functional.relu(torch.mm(x, self.rand_weight.data) + 1)\n",
    "        \n",
    "        # 复用全连接层。等价于两个全连接层共享参数\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        # 控制流,这里我们需要调用item函数来返回标量进行比较\n",
    "        while x.norm().item > 1:\n",
    "            x /= 2\n",
    "        if x.norm().item < 0.8:\n",
    "            x *= 10\n",
    "        return x.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T08:44:33.099084Z",
     "start_time": "2024-11-13T08:44:33.088059300Z"
    }
   },
   "id": "b8c247154898bfaa",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FancyMLP(\n",
      "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
      ")\n",
      "tensor([[0.4840, 0.8566, 0.4564, 0.9277, 0.0792, 0.7144, 0.6244, 0.7763, 0.6368,\n",
      "         0.7236, 0.7780, 0.8287, 0.9130, 0.1909, 0.8145, 0.1106, 0.7212, 0.5668,\n",
      "         0.3767, 0.4072],\n",
      "        [0.6896, 0.4722, 0.0433, 0.0655, 0.4583, 0.8127, 0.8067, 0.0463, 0.7229,\n",
      "         0.0962, 0.3270, 0.1076, 0.9315, 0.4078, 0.5247, 0.2931, 0.7087, 0.1210,\n",
      "         0.4497, 0.0967]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(2, 20)\n",
    "net = FancyMLP()\n",
    "print(net)\n",
    "print(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-13T08:44:53.287770400Z",
     "start_time": "2024-11-13T08:44:53.237754400Z"
    }
   },
   "id": "d0b6e3460946d021",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8c5c3601f847e7eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
